{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0CWX9rD3rWCb"
   },
   "outputs": [],
   "source": [
    "# Threat Zone Prediction Model Evaluation\n",
    "\n",
    "# This notebook evaluates our trained models on test data and explores their performance in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shapely in d:\\conda\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.21 in d:\\conda\\lib\\site-packages (from shapely) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyproj in d:\\conda\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: certifi in d:\\conda\\lib\\site-packages (from pyproj) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pp22YGHKraQK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: c:\\Users\\Nidhi\\model\\notebooks\n",
      "Project root added to sys.path: c:\\Users\\Nidhi\\model\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_curve, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "import joblib\n",
    "\n",
    "# Add parent directory to path for importing modules\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Project root added to sys.path:\", os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "\n",
    "from models.threat_model import ThreatModel\n",
    "from models.explosion_model import ExplosionModel\n",
    "from models.dispersion_model import DispersionModel\n",
    "from models.preprocessing import generate_synthetic_data\n",
    "from utils.geo_utils import calculate_threat_zone\n",
    "\n",
    "from config import Config\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6qyhZJ-NreJo"
   },
   "outputs": [],
   "source": [
    "## Load Models and Test Data\n",
    "from utils.visualization import _polygon_to_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oN_dkPAFrgeD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\condA\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator GradientBoostingRegressor from version 1.3.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "Error loading explosion model: No module named 'sklearn.ensemble._gb_losses'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (100, 5) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Nidhi\\model\\models\\explosion_model.py:30\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a default model when no trained model is available\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     base_model \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32md:\\condA\\Lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32md:\\condA\\Lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n",
      "File \u001b[1;32md:\\condA\\Lib\\pickle.py:1205\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1205\u001b[0m         dispatch[key[\u001b[38;5;241m0\u001b[39m]](\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n",
      "File \u001b[1;32md:\\condA\\Lib\\pickle.py:1530\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_class(module, name))\n",
      "File \u001b[1;32md:\\condA\\Lib\\pickle.py:1572\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1571\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[1;32m-> 1572\u001b[0m \u001b[38;5;28m__import__\u001b[39m(module, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.ensemble._gb_losses'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the models\u001b[39;00m\n\u001b[0;32m      2\u001b[0m threat_model \u001b[38;5;241m=\u001b[39m ThreatModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/saved/threat_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m explosion_model \u001b[38;5;241m=\u001b[39m ExplosionModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/saved/explosion_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m dispersion_model \u001b[38;5;241m=\u001b[39m DispersionModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/saved/dispersion_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Generate test data if it doesn't exist\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nidhi\\model\\models\\explosion_model.py:37\u001b[0m, in \u001b[0;36mExplosionModel.__init__\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     36\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading explosion model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_default_model()\n",
      "File \u001b[1;32mc:\\Users\\Nidhi\\model\\models\\explosion_model.py:48\u001b[0m, in \u001b[0;36mExplosionModel._create_default_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m X_dummy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# 2 features (gas concentration, temperature)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m y_dummy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# 5 outputs (energy, radius, duration, overpressure, radiation)\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(X_dummy, y_dummy)\n\u001b[0;32m     49\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated a default explosion model with random data. Train with real data ASAP.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\condA\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\condA\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_y(y\u001b[38;5;241m=\u001b[39my, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m--> 668\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# TODO: Is this still required?\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_max_features()\n\u001b[0;32m    672\u001b[0m \u001b[38;5;66;03m# self.loss is guaranteed to be a string\u001b[39;00m\n",
      "File \u001b[1;32md:\\condA\\Lib\\site-packages\\sklearn\\utils\\validation.py:1367\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1357\u001b[0m             (\n\u001b[0;32m   1358\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1363\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1364\u001b[0m         )\n\u001b[0;32m   1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1367\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1368\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1369\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (100, 5) instead."
     ]
    }
   ],
   "source": [
    "# Load the models\n",
    "threat_model = ThreatModel('../models/saved/threat_model.joblib')\n",
    "explosion_model = ExplosionModel('../models/saved/explosion_model.joblib')\n",
    "dispersion_model = DispersionModel('../models/saved/dispersion_model.joblib')\n",
    "\n",
    "# Generate test data if it doesn't exist\n",
    "try:\n",
    "    test_data = pd.read_csv('../data/test/test.csv')\n",
    "    print(f\"Loaded test data with {len(test_data)} samples\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Test data not found, generating synthetic test data\")\n",
    "    X, y = generate_synthetic_data(n_samples=1000, include_anomalies=True)\n",
    "    test_data = X.copy()\n",
    "    test_data['threat_level'] = y\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs('../data/test', exist_ok=True)\n",
    "    test_data.to_csv('../data/test/test.csv', index=False)\n",
    "    print(f\"Generated {len(test_data)} test data samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CO2X7xMYriIb"
   },
   "outputs": [],
   "source": [
    "## Evaluate Threat Detection Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wii_jkUsrkQq"
   },
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_test = test_data.drop(columns=['threat_level'])\n",
    "y_test = test_data['threat_level']\n",
    "\n",
    "# Make predictions using the threat model\n",
    "predictions = []\n",
    "scores = []\n",
    "detailed_results = []\n",
    "\n",
    "for _, row in X_test.iterrows():\n",
    "    result = threat_model.predict(\n",
    "        row['mq2'], row['mq4'], row['mq6'], row['mq8'],\n",
    "        row['temperature'], row['humidity']\n",
    "    )\n",
    "    # Store prediction (1 for high or medium risk, 0 for low risk or safe)\n",
    "    prediction = 1 if result['risk_score'] >= 0.5 else 0\n",
    "    predictions.append(prediction)\n",
    "    scores.append(result['risk_score'])\n",
    "    detailed_results.append(result)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions, zero_division=0)\n",
    "recall = recall_score(y_test, predictions, zero_division=0)\n",
    "f1 = f1_score(y_test, predictions, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoMEuPVorlrd"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Safe', 'Threat'],\n",
    "            yticklabels=['Safe', 'Threat'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YcRB3SIgrnuj"
   },
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "roc_auc = roc_auc_score(y_test, scores)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEL5HM-GrpVk"
   },
   "outputs": [],
   "source": [
    "# Plot Precision-Recall curve\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, scores)\n",
    "ap = average_precision_score(y_test, scores)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_curve, precision_curve, color='blue', lw=2,\n",
    "         label=f'Precision-Recall curve (AP = {ap:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xhwbhr4YrrRA"
   },
   "outputs": [],
   "source": [
    "## Risk Score Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZELeiKtyrus2"
   },
   "outputs": [],
   "source": [
    "# Add scores to test data\n",
    "test_data_with_scores = test_data.copy()\n",
    "test_data_with_scores['risk_score'] = scores\n",
    "\n",
    "# Plot risk score distribution by actual threat level\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=test_data_with_scores, x='risk_score', hue='threat_level',\n",
    "             bins=50, kde=True, element=\"step\")\n",
    "plt.axvline(x=0.5, color='red', linestyle='--', label='Decision Threshold (0.5)')\n",
    "plt.title('Risk Score Distribution by Actual Threat Level')\n",
    "plt.xlabel('Risk Score')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(['Decision Threshold (0.5)', 'Safe', 'Threat'])\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ohPrK2irxM8"
   },
   "outputs": [],
   "source": [
    "## Test Explosion Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlMnnC6Ery7K"
   },
   "outputs": [],
   "source": [
    "# Test explosion model with different gas concentrations\n",
    "gas_concentrations = [500, 1000, 2000, 5000]\n",
    "temperatures = [20, 30, 40, 50]\n",
    "\n",
    "results = []\n",
    "\n",
    "for gas in gas_concentrations:\n",
    "    for temp in temperatures:\n",
    "        explosion_result = explosion_model.predict(gas, temp)\n",
    "\n",
    "        # Store key parameters\n",
    "        results.append({\n",
    "            'gas_concentration': gas,\n",
    "            'temperature': temp,\n",
    "            'energy_release': explosion_result['energy_release'],\n",
    "            'fireball_radius': explosion_result['fireball_radius'],\n",
    "            'distance_to_overpressure_15kPa': explosion_result['distance_to_overpressure']['15kPa'],\n",
    "            'distance_to_radiation_10kW': explosion_result['distance_to_radiation']['10kW/m²']\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "explosion_results_df = pd.DataFrame(results)\n",
    "explosion_results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RN4xdpesr0rq"
   },
   "outputs": [],
   "source": [
    "# Visualize relationship between gas concentration, temperature, and explosion effects\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot energy release\n",
    "for temp in temperatures:\n",
    "    temp_data = explosion_results_df[explosion_results_df['temperature'] == temp]\n",
    "    axes[0, 0].plot(temp_data['gas_concentration'], temp_data['energy_release'],\n",
    "                   marker='o', label=f'Temperature: {temp}°C')\n",
    "axes[0, 0].set_title('Energy Release vs Gas Concentration')\n",
    "axes[0, 0].set_xlabel('Gas Concentration (ppm)')\n",
    "axes[0, 0].set_ylabel('Energy Release (MJ)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Plot fireball radius\n",
    "for temp in temperatures:\n",
    "    temp_data = explosion_results_df[explosion_results_df['temperature'] == temp]\n",
    "    axes[0, 1].plot(temp_data['gas_concentration'], temp_data['fireball_radius'],\n",
    "                   marker='o', label=f'Temperature: {temp}°C')\n",
    "axes[0, 1].set_title('Fireball Radius vs Gas Concentration')\n",
    "axes[0, 1].set_xlabel('Gas Concentration (ppm)')\n",
    "axes[0, 1].set_ylabel('Fireball Radius (m)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Plot distance to overpressure\n",
    "for temp in temperatures:\n",
    "    temp_data = explosion_results_df[explosion_results_df['temperature'] == temp]\n",
    "    axes[1, 0].plot(temp_data['gas_concentration'], temp_data['distance_to_overpressure_15kPa'],\n",
    "                   marker='o', label=f'Temperature: {temp}°C')\n",
    "axes[1, 0].set_title('Distance to 15kPa Overpressure vs Gas Concentration')\n",
    "axes[1, 0].set_xlabel('Gas Concentration (ppm)')\n",
    "axes[1, 0].set_ylabel('Distance (m)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Plot distance to radiation\n",
    "for temp in temperatures:\n",
    "    temp_data = explosion_results_df[explosion_results_df['temperature'] == temp]\n",
    "    axes[1, 1].plot(temp_data['gas_concentration'], temp_data['distance_to_radiation_10kW'],\n",
    "                   marker='o', label=f'Temperature: {temp}°C')\n",
    "axes[1, 1].set_title('Distance to 10kW/m² Radiation vs Gas Concentration')\n",
    "axes[1, 1].set_xlabel('Gas Concentration (ppm)')\n",
    "axes[1, 1].set_ylabel('Distance (m)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
